{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==1.5\n",
      "  Downloading https://files.pythonhosted.org/packages/04/79/a37d0b373757b4d283c674a64127bd8864d69f881c639b1ee5953e2d9301/tensorflow-1.5.0-cp36-cp36m-manylinux1_x86_64.whl (44.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 44.4MB 18kB/s eta 0:00:011  8% |██▉                             | 4.0MB 1.5MB/s eta 0:00:27    39% |████████████▋                   | 17.6MB 2.9MB/s eta 0:00:10    90% |████████████████████████████▉   | 40.0MB 1.1MB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow==1.5)\n",
      "Collecting protobuf>=3.4.0 (from tensorflow==1.5)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/f0/db040681187496d10ac50ad167a8fd5f953d115b16a7085e19193a6abfd2/protobuf-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (7.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.1MB 97kB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow==1.5)\n",
      "Collecting numpy>=1.12.1 (from tensorflow==1.5)\n",
      "  Downloading https://files.pythonhosted.org/packages/88/29/f4c845648ed23264e986cdc5fbab5f8eace1be5e62144ef69ccc7189461d/numpy-1.15.0-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.9MB 55kB/s eta 0:00:01 0% |▏                               | 71kB 211kB/s eta 0:01:06    36% |███████████▌                    | 5.0MB 1.0MB/s eta 0:00:09    43% |█████████████▊                  | 6.0MB 1.3MB/s eta 0:00:07    47% |███████████████▏                | 6.6MB 1.2MB/s eta 0:00:07    88% |████████████████████████████▎   | 12.2MB 1.5MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting absl-py>=0.1.6 (from tensorflow==1.5)\n",
      "  Downloading https://files.pythonhosted.org/packages/96/5d/18feb90462c8edaae71305716c7e8bac479fc9dface63221f808a6b95880/absl-py-0.3.0.tar.gz (84kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 1.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-tensorboard<1.6.0,>=1.5.0 (from tensorflow==1.5)\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/fa/91c06952517b4f1bc075545b062a4112e30cebe558a6b962816cb33efa27/tensorflow_tensorboard-1.5.1-py3-none-any.whl (3.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.0MB 265kB/s ta 0:00:011    58% |██████████████████▉             | 1.8MB 1.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.4.0->tensorflow==1.5)\n",
      "Collecting html5lib==0.9999999 (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5)\n",
      "  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\n",
      "\u001b[K    100% |████████████████████████████████| 890kB 576kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.10 (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5)\n",
      "  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n",
      "\u001b[K    100% |████████████████████████████████| 327kB 1.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5)\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl (78kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 2.1MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting bleach==1.5.0 (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5)\n",
      "  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: absl-py, html5lib\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/4c/16/ef/e36a23f2432e9220f8845f94e2c3abd39e7d9d1cd458d3159d\n",
      "  Running setup.py bdist_wheel for html5lib ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\n",
      "Successfully built absl-py html5lib\n",
      "Installing collected packages: protobuf, numpy, absl-py, html5lib, werkzeug, markdown, bleach, tensorflow-tensorboard, tensorflow\n",
      "  Found existing installation: html5lib 1.0.1\n",
      "    Uninstalling html5lib-1.0.1:\n",
      "      Successfully uninstalled html5lib-1.0.1\n",
      "  Found existing installation: bleach 2.1.3\n",
      "    Uninstalling bleach-2.1.3:\n",
      "      Successfully uninstalled bleach-2.1.3\n",
      "Successfully installed absl-py-0.3.0 bleach-1.5.0 html5lib-0.9999999 markdown-2.6.11 numpy-1.15.0 protobuf-3.6.0 tensorflow-1.5.0 tensorflow-tensorboard-1.5.1 werkzeug-0.14.1\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting keras\n",
      "  Downloading https://files.pythonhosted.org/packages/34/7d/b1dedde8af99bd82f20ed7e9697aac0597de3049b1f786aa2aac3b9bd4da/Keras-2.2.2-py2.py3-none-any.whl (299kB)\n",
      "\u001b[K    100% |████████████████████████████████| 307kB 698kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting h5py (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/cb/726134109e7bd71d98d1fcc717ffe051767aac42ede0e7326fd1787e5d64/h5py-2.8.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.8MB 275kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications==1.0.4 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/54/90/8f327deaa37a71caddb59b7b4aaa9d4b3e90c0e76f8c2d1572005278ddc5/Keras_Applications-1.0.4-py2.py3-none-any.whl (43kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 1.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing==1.0.2 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/71/26/1e778ebd737032749824d5cba7dbd3b0cf9234b87ab5ec79f5f0403ca7e9/Keras_Preprocessing-1.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Collecting pyyaml (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
      "\u001b[K    100% |████████████████████████████████| 276kB 1.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.14 (from keras)\n",
      "  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 31.2MB 27kB/s eta 0:00:011  19% |██████▏                         | 6.0MB 903kB/s eta 0:00:28    38% |████████████▌                   | 12.1MB 1.3MB/s eta 0:00:15    57% |██████████████████▍             | 17.9MB 590kB/s eta 0:00:23    62% |████████████████████▏           | 19.6MB 2.1MB/s eta 0:00:06    64% |████████████████████▋           | 20.0MB 17.4MB/s eta 0:00:01    77% |████████████████████████▊       | 24.1MB 1.3MB/s eta 0:00:06    78% |█████████████████████████       | 24.4MB 987kB/s eta 0:00:07    93% |█████████████████████████████▊  | 29.0MB 2.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.6/site-packages (from keras)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: h5py, keras-applications, scipy, keras-preprocessing, pyyaml, keras\n",
      "Successfully installed h5py-2.8.0 keras-2.2.2 keras-applications-1.0.4 keras-preprocessing-1.0.2 pyyaml-3.13 scipy-1.1.0\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 18.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==1.5\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load input and output sentance vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "word_em_in = './data/docspace.tsv'\n",
    "\n",
    "# load word embeddings\n",
    "word_embeddings = {}\n",
    "with open(word_em_in, 'r', encoding='utf-8') as w_in:\n",
    "    for line in w_in:\n",
    "        line = line.replace('\\n','')\n",
    "        line = line.split('\\t')\n",
    "        word_embeddings[line[0]] = np.array(line[1:]).astype(float)\n",
    "\n",
    "print(word_embeddings['hello'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83096\n"
     ]
    }
   ],
   "source": [
    "conversation_in = './data/conversation.txt'\n",
    "\n",
    "conversations_embedding_list_x = []\n",
    "conversations_embedding_list_y = []\n",
    "with open(conversation_in, 'r', encoding='utf-8') as c_in:\n",
    "    for line in c_in:\n",
    "        line = line.replace('\\n','')\n",
    "        line = line.split('\\t')\n",
    "        utterance_embedding_list = []\n",
    "        convs_len = len(line)\n",
    "        if convs_len > 1:\n",
    "            for utterance in line:\n",
    "                sentance_embedding = np.zeros(100,)\n",
    "                wcount = 0.0\n",
    "                for word in utterance.split(' '):\n",
    "                    sentance_embedding = np.add(sentance_embedding, word_embeddings[word])\n",
    "                    wcount = wcount + 1.0\n",
    "                sentance_embedding = np.divide(sentance_embedding, wcount)\n",
    "                utterance_embedding_list.append(sentance_embedding)\n",
    "            conversations_embedding_list_x.append(np.array(utterance_embedding_list[0:convs_len-1]))\n",
    "            conversations_embedding_list_y.append(np.array(utterance_embedding_list[1:]))\n",
    "\n",
    "print(len(conversations_embedding_list_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations_embedding_list_x[4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.95882023e-03  4.87052308e-03 -3.83257615e-03 -4.09026069e-03\n",
      "   1.46702823e-03 -2.40922400e-03 -1.52621231e-03  4.75336154e-04\n",
      "   3.02166946e-03  2.86797508e-03 -5.08084938e-03 -1.49146923e-05\n",
      "  -5.18533623e-03  5.25970438e-03 -8.05769585e-03  1.11989846e-03\n",
      "  -6.09444015e-03  1.28499023e-03  1.56277531e-03 -3.17969208e-03\n",
      "   9.44207692e-04 -2.36952077e-03  1.70005231e-04 -1.20561015e-03\n",
      "  -1.29022769e-03  3.36334077e-04 -1.51560385e-03 -2.19190562e-03\n",
      "   5.63522515e-03  3.19848000e-03 -1.01176892e-02 -3.77960223e-03\n",
      "   1.69216869e-03  5.55467915e-03  7.07473569e-03 -3.84569231e-04\n",
      "  -2.08149769e-03  3.45842208e-03 -4.44513077e-03 -1.24904154e-03\n",
      "  -1.51096923e-03 -4.64181000e-04  2.47452000e-04 -1.40265846e-03\n",
      "  -1.60140400e-03  1.68608038e-03 -1.59416308e-03 -6.28483841e-03\n",
      "   9.17189231e-04 -4.78098615e-03  4.01535015e-03  1.63027692e-05\n",
      "  -2.11582808e-03 -3.30772462e-03  4.10048846e-03 -7.49368208e-03\n",
      "  -2.66846623e-03  2.74490154e-03  3.52085846e-03  5.35713077e-03\n",
      "  -4.61600915e-03 -4.36240108e-03  1.63408077e-03 -1.02711215e-02\n",
      "  -6.29228000e-03  2.96659922e-03 -7.34466046e-03 -2.45897808e-03\n",
      "   5.64101292e-03  1.23409309e-03  5.85978623e-03 -2.71536338e-03\n",
      "   4.01977177e-03  1.59429915e-03 -2.49089623e-03 -2.94199887e-03\n",
      "  -1.32702638e-02  3.83666600e-03 -5.59065385e-04 -2.26192769e-03\n",
      "   1.49151000e-03 -2.20803438e-03  2.01931769e-03  7.36703909e-03\n",
      "   7.05193592e-03 -7.87277115e-03  1.09552769e-03  1.92782792e-03\n",
      "   3.85755077e-03  1.25517208e-03 -3.26472431e-03  4.80785215e-03\n",
      "   2.04163500e-03  1.94660892e-03 -4.79404468e-03 -6.81865231e-03\n",
      "  -4.18023846e-04  2.86843846e-03  3.51698462e-04  9.75754231e-03]\n",
      " [-5.28458000e-03  1.09978000e-02  2.32214000e-02 -1.31779000e-02\n",
      "   2.09839000e-02 -2.06691000e-02 -8.52100000e-03 -7.98236000e-03\n",
      "  -9.85546000e-03  6.65196000e-04 -5.02427000e-03 -1.63935000e-02\n",
      "  -1.15325000e-02  2.24692000e-02 -2.32400000e-02 -2.56802000e-02\n",
      "  -4.74364000e-03 -2.40170000e-02 -1.30605000e-02  1.37525000e-02\n",
      "  -3.25085000e-02 -1.63569000e-02 -2.65387000e-02 -3.96658000e-03\n",
      "   2.57638000e-03  8.40562000e-03 -9.11370000e-03  3.94675000e-03\n",
      "   3.77982000e-03  8.61953000e-04  3.56981000e-02  7.03920000e-03\n",
      "  -1.95060000e-02  1.25919000e-02  3.92743000e-02 -5.35184000e-04\n",
      "  -2.27947000e-02  2.66696000e-03 -3.86252000e-03 -2.13710000e-02\n",
      "   5.73420000e-03  2.06704000e-02 -5.94297000e-02 -4.76200000e-03\n",
      "   3.77611000e-03  1.67640000e-03 -1.23961000e-02  2.29751000e-02\n",
      "   9.61153000e-03 -6.50080000e-03  1.85795000e-02 -1.67283000e-03\n",
      "   1.37246000e-02 -1.63473000e-02  8.17795000e-03 -1.74951000e-02\n",
      "  -1.87482000e-02 -3.80613000e-03  2.08797000e-02  2.24233000e-03\n",
      "   3.11917000e-02  7.44482000e-03 -3.48517000e-03 -8.55039000e-03\n",
      "   4.79968000e-03 -1.23170000e-02 -3.59887000e-02 -1.77527000e-02\n",
      "   1.22852000e-02  1.98993000e-03  1.99835000e-02  3.25699000e-03\n",
      "  -1.70438000e-02 -1.46471000e-02 -6.48831000e-03  2.49381000e-02\n",
      "  -2.57756000e-03  3.26258000e-03  2.86348000e-02 -1.81199000e-02\n",
      "   1.02664000e-02 -1.86234000e-02  5.40727000e-03  2.16473000e-03\n",
      "  -1.12314000e-02 -1.32706000e-02  9.15231000e-03 -1.55540000e-02\n",
      "   2.11809000e-02  7.48604000e-03  1.74529000e-02  2.84029000e-02\n",
      "   1.29064000e-02  2.66979000e-02 -1.84871000e-03  2.37611000e-02\n",
      "   3.00361000e-03 -2.51987000e-03  7.83522000e-03  1.24366000e-02]\n",
      " [ 1.78798073e-03  1.50903385e-04  5.47277829e-03 -2.44784404e-03\n",
      "  -6.34547038e-04 -2.05799173e-03  1.87822642e-03  2.43861115e-03\n",
      "  -4.46138692e-03 -4.31684615e-04  1.06746427e-03 -6.69467558e-03\n",
      "  -2.81051008e-03  2.87610521e-03 -4.28899654e-03  9.52752077e-04\n",
      "  -1.00121242e-03 -2.19542515e-03  4.37916808e-03  2.28546004e-03\n",
      "  -3.16968231e-03 -1.47679923e-03 -9.40029615e-04 -3.78489556e-03\n",
      "  -2.19935515e-03  2.05647552e-03  1.86177000e-05 -2.90534904e-03\n",
      "   3.99433154e-04  1.59745692e-04  4.72237285e-03  2.25317273e-03\n",
      "  -6.23955546e-03  4.48335250e-04 -3.15000385e-04 -2.83409254e-03\n",
      "  -2.30096038e-04  1.38599785e-03 -4.19049887e-03 -6.55787196e-03\n",
      "   3.41196691e-03  2.06911235e-03 -5.13032100e-03  4.19039538e-04\n",
      "   1.62968985e-03  1.18866192e-03 -2.54971846e-03  2.22942454e-03\n",
      "   2.36896073e-03 -1.42014235e-03 -7.74490692e-04 -1.16464873e-03\n",
      "   4.49106800e-03 -8.23747385e-04  5.28535562e-03  3.56131750e-03\n",
      "  -1.37316800e-03 -6.10665008e-03 -2.73637577e-03  1.62255423e-03\n",
      "  -2.34251908e-03  8.39772385e-04 -1.01781032e-03  9.57879000e-04\n",
      "  -2.05196588e-03 -3.35429025e-03 -4.90861238e-03 -2.02983158e-03\n",
      "   3.85030154e-03  3.24581731e-03  6.04240269e-03  1.25930385e-04\n",
      "  -2.28047992e-03 -4.48755731e-04  2.12489396e-03 -7.10707308e-05\n",
      "  -2.74765088e-03 -2.89584115e-03 -2.19125265e-03 -3.58541904e-03\n",
      "   8.74045538e-04  3.19706154e-05  1.59475815e-03  4.59247888e-03\n",
      "   1.62037308e-03 -1.50757165e-03  2.41283077e-04 -1.05083577e-03\n",
      "   2.75441421e-03 -2.64110781e-03  4.86034827e-03  4.90472077e-03\n",
      "   4.27478735e-03  6.95096562e-03 -1.25268538e-03 -8.34721808e-03\n",
      "  -4.38523542e-03  9.68006577e-04  2.50395588e-03 -4.96417846e-04]]\n",
      "[[-5.28458000e-03  1.09978000e-02  2.32214000e-02 -1.31779000e-02\n",
      "   2.09839000e-02 -2.06691000e-02 -8.52100000e-03 -7.98236000e-03\n",
      "  -9.85546000e-03  6.65196000e-04 -5.02427000e-03 -1.63935000e-02\n",
      "  -1.15325000e-02  2.24692000e-02 -2.32400000e-02 -2.56802000e-02\n",
      "  -4.74364000e-03 -2.40170000e-02 -1.30605000e-02  1.37525000e-02\n",
      "  -3.25085000e-02 -1.63569000e-02 -2.65387000e-02 -3.96658000e-03\n",
      "   2.57638000e-03  8.40562000e-03 -9.11370000e-03  3.94675000e-03\n",
      "   3.77982000e-03  8.61953000e-04  3.56981000e-02  7.03920000e-03\n",
      "  -1.95060000e-02  1.25919000e-02  3.92743000e-02 -5.35184000e-04\n",
      "  -2.27947000e-02  2.66696000e-03 -3.86252000e-03 -2.13710000e-02\n",
      "   5.73420000e-03  2.06704000e-02 -5.94297000e-02 -4.76200000e-03\n",
      "   3.77611000e-03  1.67640000e-03 -1.23961000e-02  2.29751000e-02\n",
      "   9.61153000e-03 -6.50080000e-03  1.85795000e-02 -1.67283000e-03\n",
      "   1.37246000e-02 -1.63473000e-02  8.17795000e-03 -1.74951000e-02\n",
      "  -1.87482000e-02 -3.80613000e-03  2.08797000e-02  2.24233000e-03\n",
      "   3.11917000e-02  7.44482000e-03 -3.48517000e-03 -8.55039000e-03\n",
      "   4.79968000e-03 -1.23170000e-02 -3.59887000e-02 -1.77527000e-02\n",
      "   1.22852000e-02  1.98993000e-03  1.99835000e-02  3.25699000e-03\n",
      "  -1.70438000e-02 -1.46471000e-02 -6.48831000e-03  2.49381000e-02\n",
      "  -2.57756000e-03  3.26258000e-03  2.86348000e-02 -1.81199000e-02\n",
      "   1.02664000e-02 -1.86234000e-02  5.40727000e-03  2.16473000e-03\n",
      "  -1.12314000e-02 -1.32706000e-02  9.15231000e-03 -1.55540000e-02\n",
      "   2.11809000e-02  7.48604000e-03  1.74529000e-02  2.84029000e-02\n",
      "   1.29064000e-02  2.66979000e-02 -1.84871000e-03  2.37611000e-02\n",
      "   3.00361000e-03 -2.51987000e-03  7.83522000e-03  1.24366000e-02]\n",
      " [ 1.78798073e-03  1.50903385e-04  5.47277829e-03 -2.44784404e-03\n",
      "  -6.34547038e-04 -2.05799173e-03  1.87822642e-03  2.43861115e-03\n",
      "  -4.46138692e-03 -4.31684615e-04  1.06746427e-03 -6.69467558e-03\n",
      "  -2.81051008e-03  2.87610521e-03 -4.28899654e-03  9.52752077e-04\n",
      "  -1.00121242e-03 -2.19542515e-03  4.37916808e-03  2.28546004e-03\n",
      "  -3.16968231e-03 -1.47679923e-03 -9.40029615e-04 -3.78489556e-03\n",
      "  -2.19935515e-03  2.05647552e-03  1.86177000e-05 -2.90534904e-03\n",
      "   3.99433154e-04  1.59745692e-04  4.72237285e-03  2.25317273e-03\n",
      "  -6.23955546e-03  4.48335250e-04 -3.15000385e-04 -2.83409254e-03\n",
      "  -2.30096038e-04  1.38599785e-03 -4.19049887e-03 -6.55787196e-03\n",
      "   3.41196691e-03  2.06911235e-03 -5.13032100e-03  4.19039538e-04\n",
      "   1.62968985e-03  1.18866192e-03 -2.54971846e-03  2.22942454e-03\n",
      "   2.36896073e-03 -1.42014235e-03 -7.74490692e-04 -1.16464873e-03\n",
      "   4.49106800e-03 -8.23747385e-04  5.28535562e-03  3.56131750e-03\n",
      "  -1.37316800e-03 -6.10665008e-03 -2.73637577e-03  1.62255423e-03\n",
      "  -2.34251908e-03  8.39772385e-04 -1.01781032e-03  9.57879000e-04\n",
      "  -2.05196588e-03 -3.35429025e-03 -4.90861238e-03 -2.02983158e-03\n",
      "   3.85030154e-03  3.24581731e-03  6.04240269e-03  1.25930385e-04\n",
      "  -2.28047992e-03 -4.48755731e-04  2.12489396e-03 -7.10707308e-05\n",
      "  -2.74765088e-03 -2.89584115e-03 -2.19125265e-03 -3.58541904e-03\n",
      "   8.74045538e-04  3.19706154e-05  1.59475815e-03  4.59247888e-03\n",
      "   1.62037308e-03 -1.50757165e-03  2.41283077e-04 -1.05083577e-03\n",
      "   2.75441421e-03 -2.64110781e-03  4.86034827e-03  4.90472077e-03\n",
      "   4.27478735e-03  6.95096562e-03 -1.25268538e-03 -8.34721808e-03\n",
      "  -4.38523542e-03  9.68006577e-04  2.50395588e-03 -4.96417846e-04]\n",
      " [-5.59556456e-03  5.92833044e-03  2.81570011e-03 -1.60081000e-03\n",
      "   1.22312089e-03 -9.01125889e-03 -7.98365556e-04 -3.37457778e-04\n",
      "  -6.25652178e-03 -4.30733333e-04  9.58611422e-03  4.81867667e-03\n",
      "  -1.56480111e-03  3.14423078e-03 -3.15594111e-03 -4.18956778e-03\n",
      "  -2.44737911e-03  3.78633722e-03  7.79705444e-03  5.83143333e-05\n",
      "  -8.34409556e-03 -2.92539333e-03  7.04211889e-03 -1.00314600e-02\n",
      "  -2.53703111e-03  4.08101556e-03  4.66038036e-03 -7.82519222e-03\n",
      "  -2.37560167e-03 -6.91225778e-03  4.81324522e-03 -1.00196200e-03\n",
      "  -1.69446111e-02 -1.91860478e-03  4.19629333e-03 -1.12918756e-02\n",
      "   3.81362347e-03  1.34502174e-02 -6.62586000e-03 -6.39262033e-03\n",
      "  -5.03606222e-03  1.06851444e-03 -1.01114033e-02  2.96208111e-03\n",
      "   1.61547422e-03  8.38214100e-03 -8.10497778e-04 -9.29994289e-03\n",
      "  -8.46281844e-03 -1.11715033e-03 -4.47449667e-03 -2.24848667e-03\n",
      "   9.16250444e-03 -9.42843989e-03  1.09175040e-02  7.90963133e-04\n",
      "  -1.69168778e-03 -5.95299967e-03 -1.39715556e-03 -3.20855000e-03\n",
      "  -1.85678889e-03  2.62007300e-03  3.69176778e-03 -2.31779000e-03\n",
      "   4.90231667e-03 -5.94226742e-03  1.77128444e-03  4.89429600e-03\n",
      "   1.32855549e-02  5.65062111e-03  1.27364444e-03  9.83404778e-03\n",
      "  -9.45903567e-03  1.19227589e-02 -1.25880322e-02  7.84870667e-04\n",
      "  -3.89701544e-03 -1.00692778e-03 -2.62578444e-03 -7.36051111e-04\n",
      "  -6.12696667e-04 -2.87352011e-03  4.56084111e-03  1.14219000e-04\n",
      "  -1.02439878e-03 -1.21696593e-02 -3.94903889e-03  6.32720678e-03\n",
      "   2.82768222e-03 -1.72190000e-03  3.01817156e-03  5.82172222e-03\n",
      "  -1.64256222e-03  1.16609084e-02 -6.14051989e-03 -3.33635667e-03\n",
      "   1.60939111e-03 -8.91152889e-03  5.90457000e-03 -2.59316178e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(conversations_embedding_list_x[1])\n",
    "print(conversations_embedding_list_y[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM((100), batch_input_shape=(1, None, (100)), return_sequences=True))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 100)         80400     \n",
      "=================================================================\n",
      "Total params: 80,400\n",
      "Trainable params: 80,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 83096 arrays: [array([[ 1.68135413e-03, -5.56713325e-03,  5.68291917e-03,\n         1.57534167e-03,  5.47224942e-03, -2.18916038e-03,\n        -5.38892250e-03, -2.26224167e-03,  9.26792833e-04,\n        -9.52086667e-0...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-536ebb9f770a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversations_embedding_list_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconversations_embedding_list_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 83096 arrays: [array([[ 1.68135413e-03, -5.56713325e-03,  5.68291917e-03,\n         1.57534167e-03,  5.47224942e-03, -2.18916038e-03,\n        -5.38892250e-03, -2.26224167e-03,  9.26792833e-04,\n        -9.52086667e-0..."
     ]
    }
   ],
   "source": [
    "history = model.fit(conversations_embedding_list_x, conversations_embedding_list_y, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_x = np.random.randn(200000, 5, 100)\n",
    "in_y = np.random.randn(200000, 5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " - 46s - loss: 1.0013 - acc: 0.0099\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-caa0d8bc2d94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2670\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2652\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2654\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(in_x, in_y, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
