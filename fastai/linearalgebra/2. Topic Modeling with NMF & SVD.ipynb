{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains my practice notes and results of fast.ai's chaptar 2 of linear algebra: http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/2.%20Topic%20Modeling%20with%20NMF%20and%20SVD.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from sklearn)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python3.6/site-packages (from scipy)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib)\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install sklearn\n",
    "!pip install scipy\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn import decomposition\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plot\n",
    "\n",
    "%matplotlib inline \n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
    "remove = ('headers', 'footers', 'quotes')\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories, remove=remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get some glimps of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2034,), (2034,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames.shape, newsgroups_train.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract word frequency matrix (bag of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using sklearn to extract frequency matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych 2034\n",
      "  (0, 21025)\t1\n",
      "  (0, 3998)\t1\n",
      "  (0, 5546)\t1\n",
      "  (0, 10605)\t2\n",
      "  (0, 20973)\t1\n",
      "  (0, 19841)\t1\n",
      "  (0, 2408)\t1\n",
      "  (0, 14706)\t1\n",
      "  (0, 20977)\t1\n",
      "  (0, 23828)\t2\n",
      "  (0, 21208)\t1\n",
      "  (0, 15301)\t1\n",
      "  (0, 21084)\t1\n",
      "  (0, 9848)\t1\n",
      "  (0, 22878)\t1\n",
      "  (0, 13023)\t2\n",
      "  (0, 14154)\t1\n",
      "  (0, 8554)\t2\n",
      "  (0, 18949)\t1\n",
      "  (0, 18704)\t1\n",
      "  (0, 19066)\t3\n",
      "  (0, 17464)\t2\n",
      "  (0, 18699)\t1\n",
      "  (0, 7698)\t1\n",
      "  (0, 11203)\t1\n",
      "  :\t:\n",
      "  (2032, 5893)\t1\n",
      "  (2032, 11856)\t1\n",
      "  (2032, 3463)\t1\n",
      "  (2032, 3834)\t1\n",
      "  (2032, 11291)\t1\n",
      "  (2032, 24506)\t3\n",
      "  (2032, 14870)\t1\n",
      "  (2032, 5601)\t1\n",
      "  (2032, 15560)\t1\n",
      "  (2032, 16632)\t1\n",
      "  (2032, 11326)\t7\n",
      "  (2032, 11766)\t1\n",
      "  (2032, 4375)\t4\n",
      "  (2032, 8555)\t1\n",
      "  (2032, 8591)\t1\n",
      "  (2032, 21219)\t1\n",
      "  (2032, 22718)\t1\n",
      "  (2032, 9694)\t1\n",
      "  (2032, 4605)\t1\n",
      "  (2032, 9437)\t1\n",
      "  (2032, 19877)\t1\n",
      "  (2032, 21217)\t2\n",
      "  (2032, 13905)\t1\n",
      "  (2032, 14706)\t1\n",
      "  (2032, 8554)\t1\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]] (2034, 26576)\n"
     ]
    }
   ],
   "source": [
    "# specify the stopwords rule to be used when creating an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "# see newsgroups train data\n",
    "print(newsgroups_train.data[0], len(newsgroups_train.data))\n",
    "# create documents X words Matrix (bag of words Matrix)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "print(vectors) # its numpy compressed sparse metrix into a single row\n",
    "# convert the sparse matrix to dense matrix\n",
    "vectors = vectors.todense()\n",
    "print(vectors, vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00' '000' '0000' ... 'zware' 'zwarte' 'zyxel'] \n",
      " (26576,) \n",
      " ['cosmonauts' 'cosmos' 'cosponsored' 'cost' 'costa' 'costar' 'costing'\n",
      " 'costly' 'costruction' 'costs' 'cosy' 'cote' 'couched' 'couldn' 'council'\n",
      " 'councils' 'counsel' 'counselees' 'counselor' 'count']\n"
     ]
    }
   ],
   "source": [
    "# get vocabulary dictionary\n",
    "vocab = np.array(vectorizer.get_feature_names())\n",
    "print(vocab, '\\n', vocab.shape, '\\n', vocab[7000:7020])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Idea:** In this document classification problem, we assume each document is can be classified into any of the categories provided purely based on the words used in it. Each distinguishing word in a document from another contributes to the determination of class label to which it belongs.\n",
    "\n",
    "In Linear Algebra perspective, the features of each topic to be orthonormal. SVD helps us to factorize a single matrix into three matrices - one matrix with orthogonal columns, one with orthogonal rows and another diagonal matrix with relative importance of each factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
